{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w=[]\n",
    "sigma=[]\n",
    "reg=0\n",
    "eta=0\n",
    "num_layers=0\n",
    "points=0\n",
    "np.random.seed(1)\n",
    "z=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rst():\n",
    "    global z\n",
    "    z.clear()\n",
    "    wx=np.zeros((1,1))\n",
    "    z.append(wx)\n",
    "    for i in range(1,num_layers+2):\n",
    "        if(i==1):\n",
    "            zx=np.zeros((85,10))\n",
    "        else:\n",
    "            zx=np.zeros((10,10))\n",
    "        z.append(zx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise(nreg,layers,neta,cpoints):\n",
    "    global w,z,reg,eta,num_layers,points\n",
    "    w=[]\n",
    "    reg=nreg\n",
    "    eta=neta\n",
    "    num_layers=layers\n",
    "    points=cpoints\n",
    "    wx=np.zeros((1,1))\n",
    "    w.append(wx)\n",
    "    z.append(wx)\n",
    "    for i in range(1,num_layers+2):\n",
    "        if(i==1):\n",
    "            wx=np.random.random((85,10))\n",
    "            zx=np.zeros((85,10))\n",
    "        else:\n",
    "            wx=w1=np.random.random((10,10))\n",
    "            zx=np.zeros((10,10))\n",
    "        w.append(wx)\n",
    "        z.append(zx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_data(ds):        # This is one hot encoding of phi\n",
    "    df=pd.DataFrame()\n",
    "    for i in range(1,6):\n",
    "        for j in range(1,5):\n",
    "            sname=\"s\"+str(i)+\"_\"+str(j)\n",
    "            df[sname]=(ds[\"s\"+str(i)]==j)\n",
    "        for j in range(1,14):\n",
    "            sname=\"c\"+str(i)+\"_\"+str(j)\n",
    "            df[sname]=(ds[\"c\"+str(i)]==j)\n",
    "    dg=df*1\n",
    "    return dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(grad,momentum):\n",
    "    global w,z,num_layers,eta\n",
    "    #print(\"grad is \",grad)\n",
    "    for i in range (1,num_layers+2):\n",
    "        z[i]=momentum*z[i]+grad[i]\n",
    "    for i in range(1,num_layers+2):\n",
    "        w[i]=w[i]-eta*z[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_output(ds):\n",
    "    df=pd.DataFrame()\n",
    "    for i in range(10):\n",
    "        s=\"class\"+str(i)\n",
    "        df[s]=(ds[\"class\"]==i)\n",
    "    df=df*1\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function(x):\n",
    "    return (np.exp(x)/(1+np.exp(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation_function_backward(x):\n",
    "    return (1-x)*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(phi,idx):\n",
    "    global w,sigma,num_layers\n",
    "    sigma.clear()\n",
    "    sigmax=np.array(phi[idx,:])\n",
    "    sigmax.shape=1,85\n",
    "    sigma.append(sigmax)\n",
    "    for i in range(1,num_layers+2):\n",
    "       # print(\"layer \",i,\" \",sigma[i-1])\n",
    "        wx=w[i]\n",
    "       # print(\"wx.shape \",wx.shape)\n",
    "        #print(\"sigma shape \",sigma[i-1].shape)\n",
    "        sigmax=activation_function(np.dot(sigma[i-1],wx))\n",
    "        sigma.append(sigmax)\n",
    "    return sigma[num_layers+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagate(classify,idx):\n",
    "    global simga,w,reg,num_layers,points\n",
    "    #print(\"reg \",reg)\n",
    "    cs=classify[idx]\n",
    "    d=[]\n",
    "    grad=[]\n",
    "    h=[]\n",
    "    dx=np.zeros((10,1))\n",
    "    gx=np.zeros((2,1))\n",
    "    grad.append(gx)\n",
    "    for i in range(0,num_layers+2):\n",
    "        d.append(dx)\n",
    "        h.append(dx)\n",
    "    d[num_layers+1]=sigma[num_layers+1]-cs\n",
    "    h[num_layers+1]=np.multiply(d[num_layers+1],activation_function_backward(sigma[num_layers+1]))\n",
    "    h[num_layers+1]=d[num_layers+1]\n",
    "    for i in range(num_layers,0,-1):\n",
    "        d[i]=h[i+1].dot(w[i+1].T)\n",
    "        h[i]=np.multiply(d[i],activation_function_backward(sigma[i]))\n",
    "    \n",
    "    for i in range(1,num_layers+1):\n",
    "        gradx=sigma[i-1].T.dot(h[i])\n",
    "        grad.append(gradx)\n",
    "    gradx=sigma[num_layers].T.dot(h[num_layers+1])+reg*w[num_layers+1]\n",
    "    grad.append(gradx)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(ops,classify,foldpoints):\n",
    "    #print(\"ops shaep and class \",ops.shape,\" \",classify.shape)\n",
    "    e=0\n",
    "    sumw=0\n",
    "    global w,num_layers,reg\n",
    "    for i in range(1,num_layers+2):\n",
    "        sumw+=np.sum(w[i]*w[i])\n",
    "    for i in range(foldpoints):\n",
    "        x1=np.log(ops[i])\n",
    "        x2=np.log(1-ops[i])\n",
    "        r=np.multiply(classify[i],x1)+np.multiply(1-classify[i],x2)\n",
    "        e+=np.sum(r)\n",
    "    error=(e/-foldpoints)+(sumw*reg)/(2*foldpoints)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def fill():\n",
    "    learning_rate = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "    hidden_layers = [2, 3, 4]\n",
    "    reg_lambda = [ 1e-1]\n",
    "    l=[]\n",
    "    for i in range(5):\n",
    "        for j in range(3):\n",
    "            for k in range(1):\n",
    "                reg=reg_lambda[k]\n",
    "                no_of_layers=hidden_layers[j]\n",
    "                eta=learning_rate[i]\n",
    "                l.append((reg,no_of_layers,eta))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kfold(i,points,ds):\n",
    "    #print(\"ds shape \",len(ds))\n",
    "    eachfold=points/5\n",
    "    inp=embed_data(ds)\n",
    "    out=embed_output(ds)\n",
    "    #print(inp)\n",
    "    eachfold=points/5\n",
    "    bs=np.arange(points)\n",
    "    gs=np.arange(eachfold*i,eachfold*i+eachfold)\n",
    "    ls=np.setdiff1d(bs,gs)\n",
    "    #print(ls)\n",
    "    dg=inp.iloc[ls,:]\n",
    "    do=out.iloc[ls,:]\n",
    "    test_fold=inp.iloc[gs,:]\n",
    "    test_fold_out=out.iloc[gs,:]\n",
    "    classify=do.as_matrix()\n",
    "    phi=dg.as_matrix()\n",
    "    #print(\"phi sape \",phi.shape)\n",
    "    test_in=test_fold.as_matrix()\n",
    "    test_out=test_fold_out.as_matrix()\n",
    "    #print(\"sape \",test_out.shape)\n",
    "    return phi,classify,test_in,test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(ds):\n",
    "    #this function does the k fold thing\n",
    "    # first check the base\n",
    "    ds=ds.head(n=1000)\n",
    "    #print(\"len \",len(ds))\n",
    "    summary=pd.DataFrame()\n",
    "    lrate=[]\n",
    "    hidden_layer=[]\n",
    "    regulariser=[]\n",
    "    errorval=[]\n",
    "    global points\n",
    "    momentum=0.7\n",
    "    l=fill()\n",
    "    sz=len(l)\n",
    "    for i in range(sz):\n",
    "        print(\"sz \",sz)\n",
    "        initialise(l[i][0],l[i][1],l[i][2],8)\n",
    "        # reg ,laayer, eta\n",
    "        regulariser.append(l[i][0])\n",
    "        hidden_layer.append(l[i][1])\n",
    "        lrate.append(l[i][2])\n",
    "        error=0\n",
    "        for j in range(5):   # for 5 folds\n",
    "            phi,classify,test_in,test_out=kfold(j,10,ds)\n",
    "            for it in range(200):\n",
    "                rst()\n",
    "                for k in range(points):\n",
    "                    forward_propagate(phi,k)\n",
    "                    grad=backward_propagate(classify,k)\n",
    "                    update_parameters(grad,momentum)\n",
    "            m=len(test_in)\n",
    "            ops=[]\n",
    "            for t in range(m):\n",
    "                g=forward_propagate(test_in,t)\n",
    "                g=g.reshape(10)\n",
    "                ops.append(np.array(g))\n",
    "            ops=np.array(ops)\n",
    "            error+=cost(ops,test_out,m)\n",
    "        error/=5\n",
    "        errorval.append(error)\n",
    "        print(\"reg layers eta \",l[i][0],l[i][2],error)\n",
    "    hidden_layer=np.array(hidden_layer)\n",
    "    regulariser=np.array(regulariser)\n",
    "    errorval=np.array(errorval)\n",
    "    lrate=np.array(lrate)\n",
    "        \n",
    "    summary['id']=range(45)\n",
    "    summary['learning_rate']=pd.Series(lrate.flatten())\n",
    "    summary['hidden_layer']=pd.Series(hidden_layer.flatten())\n",
    "    summary['regulariser']=pd.Series(regulariser.flatten())\n",
    "    summary['average_error']=pd.Series(errorval.flatten())\n",
    "    summary.to_csv(\"summary2.csv\",index=False)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_best_calc():\n",
    "    momentum=0.7\n",
    "    ds=pd.read_csv(\"train.csv\")\n",
    "    df=pd.read_csv(\"test.csv\")\n",
    "    inphi_as_pdf=embed_data(ds)\n",
    "    phi=inphi_as_pdf.as_matrix()\n",
    "    outphi_as_pd=embed_data(df)\n",
    "    classify_as_pd=embed_output(ds[['class']])\n",
    "    classify=classify_as_pd.as_matrix()\n",
    "    res=pd.DataFrame()\n",
    "    outphi=outphi_as_pd.as_matrix()\n",
    "    initialise(2,0.0,0.1,10000)\n",
    "    for i in range(200):\n",
    "        ops=[]\n",
    "        rst()\n",
    "        for j in range(10000):\n",
    "            p=forward_propagate(phi,j)\n",
    "            grad=backward_propagate(classify,j)\n",
    "            update_parameters(grad,momentum)\n",
    "            p=p.reshape(10)\n",
    "            ops.append(p)\n",
    "        ops=np.array(ops)\n",
    "        print(cost(ops,classify,10000))\n",
    "    output=[]\n",
    "    opsz,y=outphi.shape\n",
    "    for i in range(opsz):\n",
    "        g=forward_propagate(outphi,i)\n",
    "        out=np.argmax(g)\n",
    "        out=int(out)\n",
    "        output.append(out)\n",
    "    output=np.array(output)\n",
    "    res['id']=range(opsz)\n",
    "    res['predicted_class']=pd.Series(output.flatten())\n",
    "    res.to_csv(\"kaggle_submission.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sz  15\n",
      "reg layers eta  0.1 0.1 10.4039484413\n",
      "sz  15\n",
      "reg layers eta  0.1 0.1 11.650384958\n",
      "sz  15\n",
      "reg layers eta  0.1 0.1 11.8370684929\n",
      "sz  15\n",
      "reg layers eta  0.1 0.01 10.1391196936\n",
      "sz  15\n",
      "reg layers eta  0.1 0.01 11.2995416018\n",
      "sz  15\n",
      "reg layers eta  0.1 0.01 11.6824290069\n",
      "sz  15\n",
      "reg layers eta  0.1 0.001 9.72016257341\n",
      "sz  15\n",
      "reg layers eta  0.1 0.001 10.6302845749\n",
      "sz  15\n",
      "reg layers eta  0.1 0.001 12.103406695\n",
      "sz  15\n",
      "reg layers eta  0.1 0.0001 14.3829752991\n",
      "sz  15\n",
      "reg layers eta  0.1 0.0001 15.047662605\n",
      "sz  15\n",
      "reg layers eta  0.1 0.0001 15.6360677142\n",
      "sz  15\n",
      "reg layers eta  0.1 1e-05 41.659995375\n",
      "sz  15\n",
      "reg layers eta  0.1 1e-05 46.0420210237\n",
      "sz  15\n",
      "reg layers eta  0.1 1e-05 43.3631121229\n"
     ]
    }
   ],
   "source": [
    "# here goes the main function\n",
    "# Read the data and embed it \n",
    "#embed the output vector too\n",
    "ds=pd.read_csv(\"train.csv\")\n",
    "#my_best_calc()\n",
    "model(ds)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
